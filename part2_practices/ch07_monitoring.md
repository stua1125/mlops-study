# CHAPTER 7. 모니터링과 피드백 루프

이 장에서는 운영 환경에서 머신러닝 모델의 성능을 지속적으로 관찰하고, 변화에 대응하여 재학습과 피드백을 설계하는 방법을 다룹니다.

---

## 7.1 모델을 얼마나 자주 재학습시켜야 할까?
- **데이터 드리프트**와 **개념 드리프트**의 발생 빈도에 기반해 재학습 주기를 결정
- **배치 재학습** vs **지속 학습(Continuous Training)**
- 기준: 성능 저하 임계값(예: 정확도 5% 하락), 비즈니스 요구사항

## 7.2 모델 성능 저하
- 성능 저하 원인: 입력 데이터 분포 변화, 특성 엔지니어링 변경, 환경 변화
- 모니터링 대상 지표: 정확도(Accuracy), 정밀도(Precision), 재현율(Recall), F1, RMSE 등
- **알림(Alerts)** 설정: 지표가 임계값을 벗어나면 자동 알림

## 7.3 드리프트 감지
- **데이터 드리프트** 검출 기법  
  - 통계적 검정: KS 검정(Kolmogorov–Smirnov), PSI(Population Stability Index)  
  - 분포 비교: 히스토그램, Earth Mover’s Distance  
- **개념 드리프트** 검출 방법  
  - 라벨 분포 모니터링, 성능 지표 변화 감지  
- 도구 예시: Evidently, Alibi Detect, River

## 7.4 피드백 루프
- **진단 → 라벨 수집 → 모델 재학습**의 자동화된 사이클
- **그라운드 트루스** 수집: A/B 테스트, 사용자 피드백, 휴먼 인 더 루프
- **Active Learning**: 불확실 구간에 데이터 추가 라벨링

## 7.5 마치며
- 모니터링과 피드백은 **지속적 프로세스**로 MLOps 파이프라인 핵심 요소
- 조직 내 **협업**과 **거버넌스** 연계가 중요
- 안정적 운영을 위한 대시보드와 자동화 체계 필요
